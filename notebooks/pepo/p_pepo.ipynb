{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93fb4d76-c137-4403-aa51-59c7720caca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "import quimb.tensor as qtn\n",
    "import quimb as qu\n",
    "import cotengra as ctg\n",
    "import autoray as ar\n",
    "from tcompress import register_ as reg\n",
    "from tcompress import algo_cooling as algo\n",
    "from tcompress import quf\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import nlopt\n",
    "import torch\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6f89ab9-6f81-45b4-990d-1b0b9263b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.reg_complex_svd()\n",
    "\n",
    "to_backend = algo.backend_torch(device = \"cpu\", dtype = torch.float64, requires_grad=False)\n",
    "to_backend_c = algo.backend_torch(device = \"cpu\", dtype = torch.complex128, requires_grad=False)\n",
    "to_backend_ = algo.backend_torch(device = \"cpu\", dtype = torch.float64, requires_grad=True)\n",
    "\n",
    "opt = algo.opt_(progbar=True, max_time=\"rate:1e9\", max_repeats=2**7, optlib=\"cmaes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3087dca3-8ca6-4d46-bc6d-98700414164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ITF params\n",
    "J = 1\n",
    "h = 3.05\n",
    "delta = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08d9a231-1780-477d-ad94-a1b440ea7ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lx, Ly = 3, 4       # lattice dimensions: rows x columns\n",
    "L = Lx * Ly          # total number of sites\n",
    "edges = qtn.edges_2d_square(Lx=Lx, Ly=Ly, cyclic=False)\n",
    "sites = sorted({ (site,) for edge in edges for site in edge})\n",
    "N = len(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cca37eed-8137-4fed-8a01-441bdb957f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pepo = quf.pepo_identity(Lx, Ly)\n",
    "pepo.apply_to_arrays(to_backend_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3113c757-f5b4-459f-805e-8560be393201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reza.haghshenas@quantinuum.com/time_compressed_algo/algo_cooling.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(x, dtype=dtype, device=device, requires_grad=requires_grad)\n"
     ]
    }
   ],
   "source": [
    "depth_total = 3\n",
    "params = {}\n",
    "\n",
    "p1 = 1.0 / (2.0 - 2.0**(1/3))\n",
    "p2 = - (2.0**(1/3)) / (2.0 - 2.0**(1/3))\n",
    "\n",
    "\n",
    "\n",
    "for depth in range(depth_total):\n",
    "        if depth ==1:\n",
    "            phi = -h * 0.5 * p2\n",
    "            theta = -J * 2 * 0.5 *p2\n",
    "        else:\n",
    "            phi = -h * 0.5 * p1\n",
    "            theta = -J * 2 * 0.5 *p1\n",
    "\n",
    "        params[f\"rx_depth{depth}\"] = to_backend_( torch.tensor( phi ).clone().detach() )\n",
    "        params[f\"rzz_depth{depth}\"] = to_backend_( torch.tensor( theta ).clone().detach() )\n",
    "\n",
    "\n",
    "# depth_total = 1\n",
    "# for depth in range(depth_total):\n",
    "#         phi = -h * 0.5\n",
    "#         theta = -J * 2 * 0.5\n",
    "#         params[f\"rx_depth{depth}\"] = to_backend_( torch.tensor( phi ).clone().detach() )\n",
    "#         params[f\"rzz_depth{depth}\"] = to_backend_( torch.tensor( theta ).clone().detach() )\n",
    "\n",
    "\n",
    "\n",
    "pepo = algo.skeleten_pepo(params, edges, sites, depth_total=depth_total,contract=True,\n",
    "                                  to_backend=to_backend_c, Lx=Lx, Ly=Ly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db22dfae-2d0b-4d0e-a2b8-caaec4bf35f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_, skeleton = qtn.pack(pepo)\n",
    "# params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c31a7ff-71ac-4555-8290-67983c06b79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_su = qu.load_from_disk(f\"store_state/info_su\")\n",
    "info_bp = qu.load_from_disk(f\"store_state/info_bp\")\n",
    "\n",
    "pepo_fix = info_su[\"tn\"]\n",
    "# pepo_fix = info_bp[\"pepo\"]\n",
    "\n",
    "# pepo_fix = qu.load_from_disk(\"store/pepo\")\n",
    "# pepo_fix = qu.load_from_disk(\"store/U_tn\")\n",
    "\n",
    "#pepo_fix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71396098-e1e8-489a-b2dd-83b084bf05f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<samp style='font-size: 12px;'><details><summary><b style=\"color: #e589cf;\">TensorNetworkGenVector</b>(tensors=12, indices=41)</summary><samp style='font-size: 12px;'><details><summary><b style=\"color: #e55471;\">Tensor</b>(shape=(<b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #828fdd;\">2</b>, <b style=\"color: #828fdd;\">2</b>), inds=[<b style=\"color: #9740d8;\">_88f5e9AAAAA</b>, <b style=\"color: #9290d2;\">_88f5e9AAAAB</b>, <b style=\"color: #d678af;\">b0,0</b>, <b style=\"color: #5fce5e;\">k0,0</b>], tags={<b style=\"color: #d2b137;\">I0</b>, <b style=\"color: #d44388;\">X0</b>, <b style=\"color: #b1d42e;\">Y0</b>}),</summary>backend=<b style=\"color: #634cdc;\">torch</b>, dtype=<b style=\"color: #71d3d0;\">torch.complex128</b>, data=...</details></samp><samp style='font-size: 12px;'><details><summary><b style=\"color: #e55471;\">Tensor</b>(shape=(<b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #828fdd;\">2</b>, <b style=\"color: #828fdd;\">2</b>), inds=[<b style=\"color: #cd7ec9;\">_88f5e9AAAAC</b>, <b style=\"color: #d36877;\">_88f5e9AAAAD</b>, <b style=\"color: #9290d2;\">_88f5e9AAAAB</b>, <b style=\"color: #e5677f;\">b0,1</b>, <b style=\"color: #de9a98;\">k0,1</b>], tags={<b style=\"color: #dd65d9;\">I3</b>, <b style=\"color: #d44388;\">X0</b>, <b style=\"color: #6c45d0;\">Y1</b>}),</summary>backend=<b style=\"color: #634cdc;\">torch</b>, dtype=<b style=\"color: #71d3d0;\">torch.complex128</b>, data=...</details></samp><samp style='font-size: 12px;'><details><summary><b style=\"color: #e55471;\">Tensor</b>(shape=(<b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #828fdd;\">2</b>, <b style=\"color: #828fdd;\">2</b>), inds=[<b style=\"color: #e1506f;\">_88f5e9AAAAE</b>, <b style=\"color: #b691d6;\">_88f5e9AAAAF</b>, <b style=\"color: #d36877;\">_88f5e9AAAAD</b>, <b style=\"color: #d08ca9;\">b0,2</b>, <b style=\"color: #50d0ac;\">k0,2</b>], tags={<b style=\"color: #b2de5f;\">I6</b>, <b style=\"color: #d44388;\">X0</b>, <b style=\"color: #3fdd7b;\">Y2</b>}),</summary>backend=<b style=\"color: #634cdc;\">torch</b>, dtype=<b style=\"color: #71d3d0;\">torch.complex128</b>, data=...</details></samp><samp style='font-size: 12px;'><details><summary><b style=\"color: #e55471;\">Tensor</b>(shape=(<b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #828fdd;\">2</b>, <b style=\"color: #828fdd;\">2</b>), inds=[<b style=\"color: #3bddc9;\">_88f5e9AAAAG</b>, <b style=\"color: #b691d6;\">_88f5e9AAAAF</b>, <b style=\"color: #d75355;\">b0,3</b>, <b style=\"color: #69d040;\">k0,3</b>], tags={<b style=\"color: #d74979;\">I9</b>, <b style=\"color: #d44388;\">X0</b>, <b style=\"color: #63d5a7;\">Y3</b>}),</summary>backend=<b style=\"color: #634cdc;\">torch</b>, dtype=<b style=\"color: #71d3d0;\">torch.complex128</b>, data=...</details></samp><samp style='font-size: 12px;'><details><summary><b style=\"color: #e55471;\">Tensor</b>(shape=(<b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #828fdd;\">2</b>, <b style=\"color: #828fdd;\">2</b>), inds=[<b style=\"color: #cedb43;\">_88f5e9AAAAH</b>, <b style=\"color: #d78dde;\">_88f5e9AAAAI</b>, <b style=\"color: #9740d8;\">_88f5e9AAAAA</b>, <b style=\"color: #c141de;\">b1,0</b>, <b style=\"color: #84ce75;\">k1,0</b>], tags={<b style=\"color: #d19b78;\">I1</b>, <b style=\"color: #6fe251;\">X1</b>, <b style=\"color: #b1d42e;\">Y0</b>}),</summary>backend=<b style=\"color: #634cdc;\">torch</b>, dtype=<b style=\"color: #71d3d0;\">torch.complex128</b>, data=...</details></samp><samp style='font-size: 12px;'><details><summary><b style=\"color: #e55471;\">Tensor</b>(shape=(<b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #828fdd;\">2</b>, <b style=\"color: #828fdd;\">2</b>), inds=[<b style=\"color: #d02e47;\">_88f5e9AAAAJ</b>, <b style=\"color: #dfcc9b;\">_88f5e9AAAAK</b>, <b style=\"color: #cd7ec9;\">_88f5e9AAAAC</b>, <b style=\"color: #d78dde;\">_88f5e9AAAAI</b>, <b style=\"color: #b98bcf;\">b1,1</b>, <b style=\"color: #d29586;\">k1,1</b>], tags={<b style=\"color: #998ad1;\">I4</b>, <b style=\"color: #6fe251;\">X1</b>, <b style=\"color: #6c45d0;\">Y1</b>}),</summary>backend=<b style=\"color: #634cdc;\">torch</b>, dtype=<b style=\"color: #71d3d0;\">torch.complex128</b>, data=...</details></samp><samp style='font-size: 12px;'><details><summary><b style=\"color: #e55471;\">Tensor</b>(shape=(<b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #828fdd;\">2</b>, <b style=\"color: #828fdd;\">2</b>), inds=[<b style=\"color: #8bde98;\">_88f5e9AAAAL</b>, <b style=\"color: #becf50;\">_88f5e9AAAAM</b>, <b style=\"color: #e1506f;\">_88f5e9AAAAE</b>, <b style=\"color: #dfcc9b;\">_88f5e9AAAAK</b>, <b style=\"color: #d1c274;\">b1,2</b>, <b style=\"color: #dd4dba;\">k1,2</b>], tags={<b style=\"color: #5582d6;\">I7</b>, <b style=\"color: #6fe251;\">X1</b>, <b style=\"color: #3fdd7b;\">Y2</b>}),</summary>backend=<b style=\"color: #634cdc;\">torch</b>, dtype=<b style=\"color: #71d3d0;\">torch.complex128</b>, data=...</details></samp><samp style='font-size: 12px;'><details><summary><b style=\"color: #e55471;\">Tensor</b>(shape=(<b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #828fdd;\">2</b>, <b style=\"color: #828fdd;\">2</b>), inds=[<b style=\"color: #d494d8;\">_88f5e9AAAAN</b>, <b style=\"color: #3bddc9;\">_88f5e9AAAAG</b>, <b style=\"color: #becf50;\">_88f5e9AAAAM</b>, <b style=\"color: #d438cd;\">b1,3</b>, <b style=\"color: #afe152;\">k1,3</b>], tags={<b style=\"color: #4e2bd3;\">I10</b>, <b style=\"color: #6fe251;\">X1</b>, <b style=\"color: #63d5a7;\">Y3</b>}),</summary>backend=<b style=\"color: #634cdc;\">torch</b>, dtype=<b style=\"color: #71d3d0;\">torch.complex128</b>, data=...</details></samp><samp style='font-size: 12px;'><details><summary><b style=\"color: #e55471;\">Tensor</b>(shape=(<b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #828fdd;\">2</b>, <b style=\"color: #828fdd;\">2</b>), inds=[<b style=\"color: #dce52f;\">_88f5e9AAAAO</b>, <b style=\"color: #cedb43;\">_88f5e9AAAAH</b>, <b style=\"color: #cfe053;\">b2,0</b>, <b style=\"color: #aa87d0;\">k2,0</b>], tags={<b style=\"color: #dd5dd7;\">I2</b>, <b style=\"color: #c654d5;\">X2</b>, <b style=\"color: #b1d42e;\">Y0</b>}),</summary>backend=<b style=\"color: #634cdc;\">torch</b>, dtype=<b style=\"color: #71d3d0;\">torch.complex128</b>, data=...</details></samp><samp style='font-size: 12px;'><details><summary><b style=\"color: #e55471;\">Tensor</b>(shape=(<b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #828fdd;\">2</b>, <b style=\"color: #828fdd;\">2</b>), inds=[<b style=\"color: #7ed876;\">_88f5e9AAAAP</b>, <b style=\"color: #d02e47;\">_88f5e9AAAAJ</b>, <b style=\"color: #dce52f;\">_88f5e9AAAAO</b>, <b style=\"color: #bd7ed5;\">b2,1</b>, <b style=\"color: #e1962d;\">k2,1</b>], tags={<b style=\"color: #97dddc;\">I5</b>, <b style=\"color: #c654d5;\">X2</b>, <b style=\"color: #6c45d0;\">Y1</b>}),</summary>backend=<b style=\"color: #634cdc;\">torch</b>, dtype=<b style=\"color: #71d3d0;\">torch.complex128</b>, data=...</details></samp><samp style='font-size: 12px;'><details><summary><b style=\"color: #e55471;\">Tensor</b>(shape=(<b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #828fdd;\">2</b>, <b style=\"color: #828fdd;\">2</b>), inds=[<b style=\"color: #c187cd;\">_88f5e9AAAAQ</b>, <b style=\"color: #8bde98;\">_88f5e9AAAAL</b>, <b style=\"color: #7ed876;\">_88f5e9AAAAP</b>, <b style=\"color: #5ae3e2;\">b2,2</b>, <b style=\"color: #936adf;\">k2,2</b>], tags={<b style=\"color: #8a3dd8;\">I8</b>, <b style=\"color: #c654d5;\">X2</b>, <b style=\"color: #3fdd7b;\">Y2</b>}),</summary>backend=<b style=\"color: #634cdc;\">torch</b>, dtype=<b style=\"color: #71d3d0;\">torch.complex128</b>, data=...</details></samp><samp style='font-size: 12px;'><details><summary><b style=\"color: #e55471;\">Tensor</b>(shape=(<b style=\"color: #cee54f;\">12</b>, <b style=\"color: #cee54f;\">12</b>, <b style=\"color: #828fdd;\">2</b>, <b style=\"color: #828fdd;\">2</b>), inds=[<b style=\"color: #d494d8;\">_88f5e9AAAAN</b>, <b style=\"color: #c187cd;\">_88f5e9AAAAQ</b>, <b style=\"color: #76d882;\">b2,3</b>, <b style=\"color: #8541d1;\">k2,3</b>], tags={<b style=\"color: #cc3988;\">I11</b>, <b style=\"color: #c654d5;\">X2</b>, <b style=\"color: #63d5a7;\">Y3</b>}),</summary>backend=<b style=\"color: #634cdc;\">torch</b>, dtype=<b style=\"color: #71d3d0;\">torch.complex128</b>, data=...</details></samp></details></samp>"
      ],
      "text/plain": [
       "TensorNetworkGenVector(tensors=12, indices=41)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pepo_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a72f16f9-7f26-4630-b6b4-28364e18e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm = (pepo_fix.H & pepo_fix).contract(all, optimize=opt)\n",
    "# print(complex(norm).real, complex(norm / 2**L).real)\n",
    "\n",
    "# pepo_fix = pepo_fix * (norm / 2**L)**-0.5\n",
    "# norm = (pepo_fix.H & pepo_fix).contract(all, optimize=opt)\n",
    "# print(norm, 2**L, complex(norm / 2**L))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1185914e-7b6a-4833-afd4-fde26fccda71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9496653728613783\n",
      "CPU times: user 17.8 s, sys: 3.14 s, total: 21 s\n",
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cost_opts = { \"Lx\":Lx, \"Ly\":Ly, \"depth_total\":depth_total, \"opt\":opt, \"to_backend\":to_backend_c  }\n",
    "cost = algo.cost_function(pepo_fix, params, sites, edges, **cost_opts)\n",
    "print(  float(cost)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d50d177-ea57-48f6-8c00-d3ecde324546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adam: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.25it/s, loss=3.043e-01]\n"
     ]
    }
   ],
   "source": [
    "params, loss_history = algo.adam_optimize(pepo_fix, params, sites, edges, cost_opts, its_max=10, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7aecd16b-4b0b-450e-8b9d-573647fafede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nlopt:  90%|██████████████████████████████████████████████████▍     | 18/20 [00:20<00:02,  1.16s/it, loss=3.024e-01, ||grad||=9.68e-06]\n"
     ]
    }
   ],
   "source": [
    "params, energy_hist, grad_hist = algo.nlopt_optimize(pepo_fix, params, sites, edges, cost_opts, \n",
    "                                                     cost_fn=algo.cost_function, its_max=20\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "103b26f0-2b8e-4031-be42-b933a52f236e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3024, dtype=torch.float64, grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.cost_function(pepo_fix, params, sites, edges, **cost_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "619b99d1-8e44-4298-9a52-c064fd385fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rx_depth0': tensor(-2.1417, dtype=torch.float64, requires_grad=True),\n",
       " 'rzz_depth0': tensor(-0.6255, dtype=torch.float64, requires_grad=True),\n",
       " 'rx_depth1': tensor(2.7903, dtype=torch.float64, requires_grad=True),\n",
       " 'rzz_depth1': tensor(0.4917, dtype=torch.float64, requires_grad=True),\n",
       " 'rx_depth2': tensor(-2.1417, dtype=torch.float64, requires_grad=True),\n",
       " 'rzz_depth2': tensor(-0.6255, dtype=torch.float64, requires_grad=True)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2af882c-28f6-43b2-8b20-fdf4977d5d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params['rzz_((0, 0), (0, 1))'], params['rzz_((0, 0), (1, 0))']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a755461-22b9-438c-a831-d64bcf0896ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Energy = 0.302360, Grad norm = 2.019659e-04, t = 0.776634597001248\n",
      "Step 2: Energy = 0.302360, Grad norm = 2.589117e-03, t = 0.7923399669962237\n",
      "Step 3: Energy = 0.302360, Grad norm = 5.287004e-05, t = 0.779861584000173\n",
      "Step 4: Energy = 0.302360, Grad norm = 7.995537e-05, t = 0.7634229419927578\n",
      "Step 5: Energy = 0.302360, Grad norm = 1.998848e-05, t = 0.7615565290034283\n",
      "\n",
      "Optimization finished.\n",
      "Final loss = 0.3023602063860059\n",
      "[0.30236020795890817, 0.30236043914752875, 0.30236020642958583, 0.30236020645413353, 0.3023602063860059]\n",
      "[0.00020196589464754883, 0.0025891174497722305, 5.287004448570206e-05, 7.995537157425188e-05, 1.998847549444945e-05]\n",
      "CPU times: user 1min 44s, sys: 22.1 s, total: 2min 6s\n",
      "Wall time: 3.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "energy_log = []\n",
    "grad_log = []\n",
    "dtype_ = torch.float64\n",
    "device = \"cpu\"\n",
    "\n",
    "# --- Flatten / unflatten utilities ---\n",
    "def flatten_params(trainable_params):\n",
    "    return parameters_to_vector(list(trainable_params.values())).detach().cpu().numpy()\n",
    "\n",
    "def unflatten_params(trainable_params, x):\n",
    "    vector_to_parameters(torch.tensor(x, dtype=dtype_, device=device), list(trainable_params.values()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- objective with logging ---\n",
    "step_counter = {\"n\": 0}  # mutable container for keeping step count\n",
    "\n",
    "def objective(x, grad):\n",
    "    start_time = time.perf_counter()\n",
    "    step_counter[\"n\"] += 1\n",
    "\n",
    "    # update torch params\n",
    "    unflatten_params(params, x)\n",
    "    elapsed = time.perf_counter() - start_time\n",
    "    #print(\"unflatten\",  elapsed)\n",
    "\n",
    "    #start_time = time.perf_counter()\n",
    "   \n",
    "    # zero grads\n",
    "    for p in params.values():\n",
    "        if p.grad is not None:\n",
    "            p.grad.zero_()\n",
    "    elapsed = time.perf_counter() - start_time\n",
    "    #print(\" zero grads\", elapsed)\n",
    "\n",
    "    #start_time = time.perf_counter()\n",
    "\n",
    "    # compute loss\n",
    "    loss = algo.cost_function(pepo_fix, params, sites, edges, **cost_opts)\n",
    "\n",
    "    elapsed = time.perf_counter() - start_time\n",
    "    #print(\"cost\", elapsed)\n",
    "\n",
    "    #start_time = time.perf_counter()\n",
    "    loss.backward()\n",
    "    elapsed = time.perf_counter() - start_time\n",
    "    #print(\"backward\", elapsed)\n",
    "\n",
    "    # flatten grads\n",
    "    # g = torch.cat([p.grad.reshape(-1) for p in trainable_params.values()])\n",
    "    # grad_norm = g.norm().item()\n",
    "\n",
    "    #start_time = time.perf_counter()\n",
    "    \n",
    "    # if grad.size > 0:\n",
    "    #     grad[:] = g.detach().numpy()\n",
    "    if grad.size > 0:\n",
    "        flat_grad_tensor = parameters_to_vector([p.grad for p in params.values()])\n",
    "        grad[:] = flat_grad_tensor.detach().cpu().numpy()\n",
    "        grad_norm = flat_grad_tensor.norm().item()\n",
    "    else:\n",
    "        grad_norm = float('nan')\n",
    "\n",
    "    elapsed = time.perf_counter() - start_time\n",
    "    #print(\"put_grad\", elapsed)\n",
    "\n",
    "    energy_log.append(loss.item())\n",
    "    grad_log.append(grad_norm)\n",
    "    # logging\n",
    "    print(f\"Step {step_counter['n']}: Energy = {loss.item():.6f}, Grad norm = {grad_norm:.6e}, t = {elapsed}\")\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "# --- run NLopt ---\n",
    "x0 = flatten_params(params)\n",
    "\n",
    "\n",
    "\n",
    "its_max = 12\n",
    "\n",
    "opt_nl = nlopt.opt(nlopt.LD_LBFGS, len(x0))\n",
    "# opt_nl = nlopt.opt(nlopt.LD_VAR2, len(x0))\n",
    "\n",
    "opt_nl.set_min_objective(objective)\n",
    "\n",
    "opt_nl.set_maxeval(its_max)\n",
    "\n",
    "opt_nl.set_ftol_rel(1e-8)\n",
    "opt_nl.set_xtol_rel(1e-8)\n",
    "opt_nl.set_ftol_abs(1e-8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_opt = opt_nl.optimize(x0)\n",
    "final_loss = opt_nl.last_optimum_value()\n",
    "\n",
    "print(\"\\nOptimization finished.\")\n",
    "print(\"Final loss =\", final_loss)\n",
    "\n",
    "\n",
    "print(energy_log)\n",
    "print(grad_log)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4f83184-a5fa-4b68-b162-35029da85109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step     1: InF = 0.30236021, GradNorm = 1.999e-05, dt = 0.780s\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           20\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.02360D-01    |proj g|=  1.53334D-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step     2: InF = 0.97653159, GradNorm = 3.465e-01, dt = 0.766s\n",
      "Step     3: InF = 0.30236021, GradNorm = 6.576e-05, dt = 0.773s\n",
      "\n",
      "At iterate    1    f=  3.02360D-01    |proj g|=  4.36271D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6      1      3      1     0     0   4.363D-05   3.024D-01\n",
      "  F =  0.30236020635708560     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "\n",
      "Optimization finished.\n",
      "Success: True | Status: 0\n",
      "Final loss: 0.3023602063570856\n",
      "CPU times: user 1min 2s, sys: 12.8 s, total: 1min 15s\n",
      "Wall time: 2.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# --- deps\n",
    "import time, numpy as np, torch\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# ----- CONFIG -----\n",
    "dtype_  = torch.float64\n",
    "device  = \"cpu\"\n",
    "its_max = 4\n",
    "\n",
    "# Your dict of trainable tensors (all require_grad=True, float dtype)\n",
    "# params: Dict[str, torch.Tensor]\n",
    "# cost_function(params) -> scalar torch.Tensor\n",
    "# -------------------\n",
    "\n",
    "# --- Flatten / unflatten\n",
    "def flatten_params(trainable_params):\n",
    "    return parameters_to_vector(list(trainable_params.values())).detach().cpu().numpy()\n",
    "\n",
    "def unflatten_params(trainable_params, x):\n",
    "    vector_to_parameters(torch.tensor(x, dtype=dtype_, device=device),\n",
    "                         list(trainable_params.values()))\n",
    "\n",
    "# --- Logs\n",
    "energy_log, grad_log = [], []\n",
    "step_counter = {\"n\": 0}\n",
    "\n",
    "# --- Value + gradient closure for SciPy\n",
    "def fun_and_grad(x):\n",
    "    step_counter[\"n\"] += 1\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    # load x -> torch params\n",
    "    unflatten_params(params, x)\n",
    "\n",
    "    # zero grads\n",
    "    for p in params.values():\n",
    "        if p.grad is not None:\n",
    "            p.grad.zero_()\n",
    "\n",
    "    # forward\n",
    "    loss = algo.cost_function(pepo_fix, params, sites, edges, **cost_opts)          # torch scalar\n",
    "    # backward\n",
    "    loss.backward()\n",
    "\n",
    "    # flatten grad (SciPy expects float64 numpy)\n",
    "    flat_grad = parameters_to_vector([p.grad for p in params.values()]).detach().cpu().numpy()\n",
    "    grad_norm = float(np.linalg.norm(flat_grad))\n",
    "    dt = time.perf_counter() - t0\n",
    "\n",
    "    # logs\n",
    "    energy_log.append(loss.item())\n",
    "    grad_log.append(grad_norm)\n",
    "    print(f\"Step {step_counter['n']:5d}: \"\n",
    "          f\"InF = {loss.item():.8f}, GradNorm = {grad_norm:.3e}, dt = {dt:.3f}s\")\n",
    "\n",
    "    return loss.item(), flat_grad\n",
    "\n",
    "# --- SciPy expects separate fun and jac callables, or fun that ignores jac.\n",
    "#     We wrap fun_and_grad and cache outputs to avoid double evals.\n",
    "_last_x = {\"x\": None, \"f\": None, \"g\": None}\n",
    "def fun_only(x):\n",
    "    if _last_x[\"x\"] is None or not np.array_equal(x, _last_x[\"x\"]):\n",
    "        f, g = fun_and_grad(x)\n",
    "        _last_x.update(x=x.copy(), f=f, g=g)\n",
    "    return _last_x[\"f\"]\n",
    "\n",
    "def jac_only(x):\n",
    "    if _last_x[\"x\"] is None or not np.array_equal(x, _last_x[\"x\"]):\n",
    "        f, g = fun_and_grad(x)\n",
    "        _last_x.update(x=x.copy(), f=f, g=g)\n",
    "    return _last_x[\"g\"]\n",
    "\n",
    "# --- Initial vector\n",
    "x0 = flatten_params(params)\n",
    "\n",
    "# --- Run SciPy\n",
    "res = minimize(\n",
    "    fun_only,\n",
    "    x0,\n",
    "    method=\"L-BFGS-B\",      # or \"BFGS\"\n",
    "    jac=jac_only,\n",
    "    options=dict(\n",
    "        maxiter=its_max,\n",
    "        ftol=1e-8,          # function tolerance\n",
    "        gtol=1e-8,          # gradient tolerance (BFGS); L-BFGS-B uses pgtol via 'pgtol'\n",
    "        maxcor=20,          # L-BFGS memory (default 10)\n",
    "        maxls=50,           # line-search steps\n",
    "        disp=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# --- Write back the final params (minimize returns the last x)\n",
    "unflatten_params(params, res.x)\n",
    "\n",
    "print(\"\\nOptimization finished.\")\n",
    "print(\"Success:\", res.success, \"| Status:\", res.status)\n",
    "print(\"Final loss:\", res.fun)\n",
    "# logs are in energy_log / grad_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bda1f9e-fc0c-4135-8a58-0237511ad379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}