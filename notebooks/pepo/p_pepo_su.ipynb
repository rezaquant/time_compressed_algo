{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93fb4d76-c137-4403-aa51-59c7720caca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "import quimb.tensor as qtn\n",
    "import quimb as qu\n",
    "import cotengra as ctg\n",
    "import autoray as ar\n",
    "import register_ as reg\n",
    "import algo_cooling as algo\n",
    "import quf\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import nlopt\n",
    "import torch\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "from quimb.tensor.belief_propagation.l2bp import L2BP\n",
    "from gate_arb import TensorNetworkGenVector\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6f89ab9-6f81-45b4-990d-1b0b9263b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.reg_complex_svd()\n",
    "\n",
    "to_backend = algo.backend_torch(device = \"cpu\", dtype = torch.float64, requires_grad=False)\n",
    "to_backend_c = algo.backend_torch(device = \"cpu\", dtype = torch.complex128, requires_grad=False)\n",
    "to_backend_ = algo.backend_torch(device = \"cpu\", dtype = torch.float64, requires_grad=True)\n",
    "\n",
    "opt = algo.opt_(progbar=False, max_time=\"rate:1e9\", max_repeats=128, optlib=\"cmaes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79d17148-1be9-40c3-92ec-109a13ecf4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_su = qu.load_from_disk(f\"store_state/info_su\")\n",
    "# info_bp = qu.load_from_disk(f\"store_state/info_bp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3087dca3-8ca6-4d46-bc6d-98700414164f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t 1.0 chi 20 L 16 depth 20\n"
     ]
    }
   ],
   "source": [
    "#ITF params\n",
    "J, h, chi, dt, depth = info_su[\"J\"], info_su[\"h\"], info_su[\"chi\"], info_su[\"dt\"], info_su[\"depth\"],\n",
    "Lx, Ly, L = info_su[\"Lx\"], info_su[\"Ly\"], info_su[\"L\"]\n",
    "t = depth * dt\n",
    "print(\"t\", t, \"chi\", chi, \"L\", L, \"depth\", depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3152d98b-3c70-498c-a907-4c2b682d80d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_1d, sites, site_tags = info_su[\"edges_1d\"], info_su[\"sites\"], info_su[\"site_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a176745-e113-4664-9083-2172e8093c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pepo, gauges = info_su[\"pepo\"], info_su[\"gauges\"]\n",
    "# pepo.apply_to_arrays(to_backend_c)\n",
    "# to_backend_c(pepo.exponent)\n",
    "# gauges = { u:to_backend(v)  for u, v in gauges.items()}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee486dd-f9f6-4044-995c-18a5423b13f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gauges = {}\n",
    "# pepo = info_bp[\"pepo\"]\n",
    "\n",
    "# pepo.retag_(info_su[\"map_tags\"])\n",
    "# pepo.reindex_(info_su[\"map_inds\"])\n",
    "# pepo.reindex_(info_su[\"map_inds_b\"])\n",
    "\n",
    "# pepo.view_as_(TensorNetworkGenVector,  site_tag_id='I{}',site_ind_id='k{}',)\n",
    "\n",
    "# pepo.apply_to_arrays(to_backend_c)\n",
    "\n",
    "# # pepo.gauge_all_simple_(max_iterations=100, tol=1e-6, gauges=gauges, progbar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08d9a231-1780-477d-ad94-a1b440ea7ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4082, dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pepo.exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58989126-9d43-4bb2-8c6d-9b073d159f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rezah/Documents/time_compressed_algo/algo_cooling.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(x, dtype=dtype, device=device, requires_grad=requires_grad)\n"
     ]
    }
   ],
   "source": [
    "# depth_total = 3\n",
    "# params = {}\n",
    "\n",
    "# p1 = 1.0 / (2.0 - 2.0**(1/3))\n",
    "# p2 = - (2.0**(1/3)) / (2.0 - 2.0**(1/3))\n",
    "\n",
    "\n",
    "# for depth in range(depth_total):\n",
    "#         if depth ==1:\n",
    "#             phi = -h * 0.5 * p2\n",
    "#             theta = -J * 2 * 0.5 *p2\n",
    "#         else:\n",
    "#             phi = -h * 0.5 * p1\n",
    "#             theta = -J * 2 * 0.5 *p1\n",
    "\n",
    "#         params[f\"rx_depth{depth}\"] = to_backend_( torch.tensor( phi ).clone().detach() )\n",
    "#         params[f\"rzz_depth{depth}\"] = to_backend_( torch.tensor( theta ).clone().detach() )\n",
    "\n",
    "\n",
    "depth_total = 5\n",
    "params = {}\n",
    "for depth in range(depth_total):\n",
    "        phi = -0.\n",
    "        theta = -0.\n",
    "        params[f\"rx_depth{depth}\"] = to_backend_( torch.tensor( phi ).clone().detach() )\n",
    "        params[f\"rzz_depth{depth}\"] = to_backend_( torch.tensor( theta ).clone().detach() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ede9b7b-3e78-4cef-857f-d8d86449abd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999894720899822\n",
      "CPU times: user 5.1 s, sys: 6.44 s, total: 11.5 s\n",
      "Wall time: 5.16 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:9: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:837.)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "chi = 20\n",
    "chi_mps = int(chi*1.2)\n",
    "cost_opts = { \"Lx\":Lx, \"Ly\":Ly, \"depth_total\":depth_total, \"opt\":opt, \"edges\":edges_1d, \"stable\":True  }\n",
    "cost_opts |= { \"cutoff\":0.0, \"map_tags_2d\":info_su[\"map_tags_2d\"], \"opt\":opt, \"chi\":chi, \"sites\": sites }\n",
    "cost_opts |= { \"renorm\":False, \"equalize_norms\":False, \"chi_mps\":chi_mps }\n",
    "cost_opts |= { \"pepo\":pepo, \"gauges\":gauges  }\n",
    "\n",
    "cost = algo.cost_function_su(params,  **cost_opts)\n",
    "print( float(cost) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3113c757-f5b4-459f-805e-8560be393201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adam: 100%|██████████| 1/1 [00:11<00:00, 11.15s/it, loss=1.000e+00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Loss = 0.9999894720899822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "params_list = list(params.values())\n",
    "optimizer = optim.Adam(params_list, lr=0.01)\n",
    "\n",
    "its_max = 1\n",
    "loss_history = []\n",
    "pbar = tqdm(total=its_max, desc=\"adam\", ncols=100, dynamic_ncols=True)\n",
    "\n",
    "for step in range(its_max):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pepo_ = pepo.copy()\n",
    "        gauges_ = {u: v * 1.0 for u, v in gauges.items()}\n",
    "        cost_opts |= { \"pepo\":pepo_, \"gauges\":gauges_  }\n",
    "    \n",
    "\n",
    "    loss = algo.cost_function_su(params,  **cost_opts)\n",
    "    loss.backward()  # keep graph if needed\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_history.append(loss.item())   # store scalar for plotting\n",
    "    \n",
    "    print(f\"Step {step}: Loss = {loss.item()}\")\n",
    "    pbar.set_postfix({\n",
    "            \"loss\": f\"{loss.item():.3e}\",\n",
    "        })\n",
    "    pbar.update(1)\n",
    "pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb04697f-6634-4aa3-8c6a-f66533663ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nlopt:  45%|████▌     | 18/40 [03:03<03:37,  9.90s/it, loss=9.989e-01, ||grad||=2.13e-02]"
     ]
    },
    {
     "ename": "runtime_error",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mruntime_error\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m cost_opts[\u001b[33m\"\u001b[39m\u001b[33mchi\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[32m20\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m params, energy_hist, grad_hist = \u001b[43malgo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnlopt_optimize_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost_opts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlbfgs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                                                     \u001b[49m\u001b[43mcost_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43malgo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcost_function_su\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mits_max\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\n\u001b[32m      4\u001b[39m \u001b[43m                                                    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/time_compressed_algo/algo_cooling.py:1432\u001b[39m, in \u001b[36mnlopt_optimize_\u001b[39m\u001b[34m(params, cost_opts, cost_fn, its_max, optimizer, device)\u001b[39m\n\u001b[32m   1429\u001b[39m opt_nl.set_xtol_rel(\u001b[32m1e-9\u001b[39m)\n\u001b[32m   1430\u001b[39m opt_nl.set_ftol_abs(\u001b[32m1e-9\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1432\u001b[39m x_opt = \u001b[43mopt_nl\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1433\u001b[39m final_loss = opt_nl.last_optimum_value()\n\u001b[32m   1434\u001b[39m pbar.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/envs/genpy/lib/python3.12/site-packages/nlopt/nlopt.py:454\u001b[39m, in \u001b[36mopt.optimize\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args):\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nlopt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopt_optimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mruntime_error\u001b[39m: "
     ]
    }
   ],
   "source": [
    "cost_opts[\"chi\"] = 20\n",
    "params, energy_hist, grad_hist = algo.nlopt_optimize_(params, cost_opts, device=\"cpu\", optimizer=\"lbfgs\",\n",
    "                                                     cost_fn=algo.cost_function_su, its_max=40\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e0683-207c-44d5-a851-7b0a8936d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c94f043-a16c-4458-949e-280887284847",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_opts[\"chi\"] = 16\n",
    "cost = algo.cost_function_su(params,  **cost_opts)\n",
    "print( float(cost) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08302dfe-7cee-428d-97be-05a990bd1c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Convert to CPU and detach before plotting\n",
    "names = list(params.keys())\n",
    "values = [v.detach().cpu().item() for v in params.values()]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(names, values, marker='o', linestyle='-', color='blue')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Parameter value\")\n",
    "plt.title(\"RX and RZZ parameter values by depth\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6e5b92-862f-429c-aeed-358f602d523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 5))  # compact and clean figure\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(\n",
    "    loss_history, zorder=5, label=r\"$\\chi=16$\",color=\"orange\",\n",
    "    markersize=12, linewidth=2.2, alpha=1., marker='*', linestyle='-',\n",
    "    markeredgecolor=\"whitesmoke\", mfc=\"orange\", markeredgewidth=1.4\n",
    ")\n",
    "\n",
    "plt.yscale('log')\n",
    "\n",
    "# Set axis limits\n",
    "# plt.xlim(0, max(t_l))        # adjust x-axis range if needed\n",
    "# plt.ylim(0.99, 0.99999)            # adjust y-axis range for log scale\n",
    "\n",
    "plt.ylabel(r\"$ 1- \\mathrm{Tr}\\!\\left(U^\\dagger V(\\theta)\\right) / 2^L$\", fontsize=12)\n",
    "plt.xlabel(\"Time\", fontsize=12)\n",
    "\n",
    "plt.grid(True, linestyle='--', linewidth=0.3, alpha=0.5)\n",
    "plt.tick_params(width=0.8, labelsize=12)\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_linewidth(1.)\n",
    "\n",
    "\n",
    "plt.title(rf\"Ising Model, $J=1, h=3.05$, $L = {4} \\times {4}$, $\\delta={0.05}$\", fontsize=14, color='darkred', pad=15)  # pad adds space above the plot\n",
    "\n",
    "plt.grid(color='gray', linestyle='-', linewidth=1., alpha=1.)\n",
    "plt.legend(loc='best', frameon=True, shadow=True, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a6db1-c25b-4b89-87ce-26299ac331bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
